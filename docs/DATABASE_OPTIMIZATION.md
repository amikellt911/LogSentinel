# 数据库高性能优化：连接池与并发模型 (Database Optimization)

本文档针对 `LogSentinel` 项目在未来架构中如何进一步压榨 SQLite 的性能进行深度分析。
核心议题：**使用 `thread_local` 连接 + `SQLITE_OPEN_NOMUTEX` 模式的可行性分析与实施指南。**

## 1. 现状 (Current Architecture)
*   **模式:** 单一 `sqlite3*` 连接句柄 + 全局 `std::mutex` 锁。
*   **并发:**
    *   **读:** 被 Mutex 锁住，多线程无法并行读取（即使开了 WAL）。
    *   **写:** 被 Mutex 锁住，与读互斥。
*   **瓶颈:** 所有数据库操作（包括前端查询 `/dashboard` 和后台写入 `/logs`）都在争抢同一把应用层锁。

---

## 2. 优化方案：Thread-Local Connections

### 2.1 核心思想
放弃全局的 `sqlite3*` 句柄，改为每个线程持有一个独立的连接。

```cpp
// 伪代码示例
thread_local sqlite3* t_db = nullptr; // 每个线程独享
```

### 2.2 关键配置
1.  **`SQLITE_OPEN_NOMUTEX`**:
    *   因为连接是线程私有的 (`thread_local`)，我们不需要 SQLite 内部的互斥锁来保护这个连接句柄。这减少了用户态的锁开销。
2.  **`PRAGMA journal_mode=WAL;`**:
    *   **必须开启**。WAL 模式允许“读写分离”。即：当线程 A 正在写入（持有文件写锁）时，线程 B 依然可以读取（持有文件读锁）。
    *   如果没有 WAL，线程 B 的读取会被阻塞，优化失效。
3.  **`sqlite3_busy_timeout(db, 30000);`**:
    *   **致命陷阱:** 在多连接模式下，如果线程 A 正在写，线程 B 也尝试写，SQLite 默认会立即返回 `SQLITE_BUSY` 错误，导致任务失败。
    *   **解决方案:** 必须设置 Busy Timeout（例如 30s）。告诉 SQLite：“如果忙，请帮我自动重试，直到 30秒后再放弃”。

---

## 3. 并发模型分析 (Concurrency Analysis)

采用该优化后，实际的并发行为如下：

| 场景 | 行为 | 性能提升 |
| :--- | :--- | :--- |
| **读 + 读** | **完全并行**。两个线程各自持有一个连接，互不干扰。 | ⭐⭐⭐⭐⭐ (极大提升) |
| **读 + 写** | **并行**。WAL 机制保证写操作不会阻塞读操作。 | ⭐⭐⭐⭐ |
| **写 + 写** | **串行**。SQLite 引擎限制同一时刻只能有一个 Writer。线程 B 会进入 "Busy Wait" 状态。 | ⭐ (无提升，甚至略有锁等待开销) |

**结论:**
该方案非常适合 `LogSentinel` 的场景，因为我们将拥有一个 **Interactive Pool (全读)** 和一个 **Worker Pool (读写混合)**。
Interactive Pool 的查询请求将永远不会被后台的写入任务锁住。

---

## 4. 实施风险与对策 (Pitfalls)

### 4.1 "有人说不行" 的原因分析
网上反对该方案的声音通常源于：
1.  **忘记设 `busy_timeout`:** 导致程序疯狂报错 `database is locked`。
2.  **没开 WAL:** 导致读操作依然被写锁阻塞，感觉“没提升”。
3.  **连接数过多:** 比如开了 1000 个线程，就有 1000 个连接，文件描述符耗尽。
    *   *对策:* 我们限制了线程池大小 (Total < 20)，完全没问题。

### 4.2 事务管理
使用 `thread_local` 后，跨线程的事务是不可能的（例如线程 A `BEGIN`，线程 B `COMMIT`）。
*   **对策:** 确保事务范围严格限制在单个函数/单个线程任务内。我们的 `saveRawLogBatch` 设计完全符合此要求。

---

## 5. 总结

**建议在下一阶段架构改造中实施此方案。**

它可以完美解决“AI 写入慢导致 前端查询卡顿”的问题（配合双线程池架构）。即便 AI 任务正在疯狂写入数据库，前端发起的 `SELECT` 查询依然可以毫秒级返回。
