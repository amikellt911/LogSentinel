# 项目演示与展示策略文档 (Demonstration Strategy)

本文档旨在梳理 LogSentinel 项目的展示逻辑，特别是针对毕业设计演示场景。作为“产品经理”，我们需要向“客户”（答辩老师/评审）展示项目的核心技术亮点（Map-Reduce）以及其实用价值。

## 1. 核心难点：Map-Reduce 的可视化

在我们的架构中，Map-Reduce 并非指 Hadoop 式的分布式计算，而是指**AI 驱动的流式处理管线**：
*   **Map (映射/解析):** 原始日志流 -> `analyzeBatch` -> 结构化风险分析 (每条日志独立的 Insight)。
*   **Reduce (归约/总结):** 结构化风险分析列表 -> `summarize` -> 宏观态势感知 (Batch 级别的 Global Summary)。

### 1.1 Map 的展示 (微观视角)
**目标:** 展示系统“看懂”了每一条日志。

*   **展示形式:** **“透视眼”列表 (X-Ray View)**
    *   **左侧 (Raw):** 原始的、乱糟糟的日志文本 (滚动显示)。
    *   **中间 (Process):** 一个动态的连接线或处理动画。
    *   **右侧 (Structured):** AI 解析后的卡片。
        *   高亮显示 `risk_level` (红/黄/绿)。
        *   提取出的关键字段 (如 SQL 语句、IP、错误类型)。
    *   **演示技巧:** 暂停实时流，点击某一条原始日志，展开显示其被 AI "Map" 后的结果。

### 1.2 Reduce 的展示 (宏观视角)
**目标:** 展示系统能从海量数据中“提炼”出价值，而不是仅仅罗列数据。

*   **展示形式:** **“动态态势大屏” (Batch Insight Dashboard)**
    *   **核心组件:** **实时生成的 AI 简报 (The Pulse)**。
        *   在页面顶部放置一个文本框，内容**每隔几秒自动打字机式刷新**。
        *   内容来源：`LogBatcher::processBatch` 中生成的 `global_summary`。
        *   *例子:* “过去 5 秒内，监测到 3 次高风险 SQL 注入尝试，均来自 IP 192.168.x.x，系统判定为协同攻击。”
        *   **视觉冲击点:** 让老师看到这个文字是**随着日志流入实时变动**的。这就是最直观的 "Reduce" —— 把几百行日志 Reduce 成了一句话。
    *   **辅助组件:** **动态聚合图表**。
        *   **饼图/柱状图:** 本批次 (Batch) 内的风险等级分布。随着每个 Batch 处理完，图表会有轻微跳动/重绘。
        *   这证明了后台在做实时的 `count` 和 `group by` 操作。

---

## 2. 实时日志流 vs. 历史日志流

这两个界面的受众和目的完全不同，设计上也应区分。

### 2.1 实时日志流 (The "Live" View)
**场景:** 运维人员盯着屏幕看系统是否健康，或者演示时展示“我发一个请求，系统立刻有反应”。
**关键词:** **速度、流光溢彩、即时反馈**。

*   **建议展示内容:**
    1.  **瀑布流 (Log Waterfall):** 极简模式。只显示 时间戳 | 级别 (色块) | 简短摘要。
    2.  **心跳指示器:** 显示 Backend 正在处理 Batch 的进度条或呼吸灯。
    3.  **即时报警:** 如果出现 High Risk 日志，屏幕边缘闪烁红色或弹出 Toast 通知。
*   **毕设加分点:**
    *   **双屏互动:** 你用 Postman 发送一个恶意请求 (Attack)，实时流界面立刻“捕获”并高亮显示，顶部的 "Reduce 简报" 随后立即更新提到这次攻击。

### 2.2 历史日志流 (The "History" View)
**场景:** 出了事故，事后诸葛亮，或者老板要做月度汇报。
**关键词:** **搜索、统计、深度分析**。

*   **建议展示内容:**
    1.  **高级筛选器:** 必须要有。按时间范围、按 Risk Level、按关键词搜索。
    2.  **趋势图 (Trend Analysis):** 展示选中时间段内的错误率变化曲线。这是另一种 "Reduce" (按时间维度归约)。
    3.  **详情下钻:** 点击某一条历史记录，不仅展示当时的 AI 分析，还可以展示该日志前后的上下文 (Context)。
    4.  **历史报告生成:** 一个按钮，“生成此时段分析报告”，调用 AI 对选中的历史数据再做一次超大的 "Reduce" (总结)。

---

## 3. 给“非客户”(老师) 的特供展示技巧

老师主要看工作量和技术深度。

1.  **Debug 模式/透视模式开关:**
    *   在界面做一个显眼的开关叫 "Show Architecture" 或 "Debug Info"。
    *   打开后，在界面上叠加显示当前的 QPS、Batch 处理耗时、AI Token 消耗量。
    *   **目的:** 告诉老师“我不只是调了 API，我还做了性能监控和批处理优化”。

2.  **对比演示 (Before/After):**
    *   准备一组难懂的 Log。
    *   先展示“传统模式”：一堆看不懂的文本。
    *   点击“开启 AI 分析”：瞬间变成结构化的、带有风险标签的、有总结的可视化图表。
    *   **目的:** 突出项目的核心价值。

3.  **压力测试演示:**
    *   用脚本高并发发送日志。
    *   展示“实时流”虽然刷得飞快，但界面不卡顿 (前端虚拟滚动)，且“Reduce 简报”依然能稳健地每隔几秒产出一次宏观总结。
    *   **目的:** 展示 `LogBatcher` 和环形缓冲区的稳定性。

## 4. 总结 (Action Plan)

1.  **前端:** 重点打造 **Dashboard (实时聚合)** 和 **LogStream (实时流)** 两个页面。
2.  **后端:** 确保 `global_summary` 能通过 API 单独获取，或者包含在 WebSocket/轮询的 Payload 中。
3.  **演示脚本:** 编写一个自动化脚本 (Python)，模拟“正常流量”、“高频报错”、“恶意攻击”三种模式，在演示时按需触发，配合前端界面展示变化。
