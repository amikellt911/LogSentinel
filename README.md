# LogSentinel 项目

LogSentinel 是一个基于 C++ 实现的高性能日志分析服务。

项目采用 Reactor 模式处理网络I/O，并通过独立的线程池执行业务逻辑，以实现高并发和低延迟。

## 待优化项汇总 (Optimization Roadmap)

以下是根据各模块的 `README` 文件总结的未来优化方向列表。

### 1. 架构与核心逻辑 (Architecture & Core Logic)

-   **HTTP层重构**:
    -   引入专门的 **路由类** 来替代现有的简单回调，以更优雅地管理 URL 与处理函数的映射关系。
    -   设计并使用 `RequestContext` 类来封装请求上下文，取代目前分散在 `httpCallback` 参数中的数据，使信息传递更集中、更可扩展。
-   **增强系统韧性**:
    -   为 `SaveLog` 等关键的持久化操作增加 **重试或死信队列** 机制，当操作失败时（如数据库繁忙），能自动重试或将失败的日志存入死信队列，供后续分析处理。

### 2. 性能与并发 (Performance & Concurrency)

-   **升级为 gRPC 通信**:
    -   在功能验证通过后，将服务间（如 C++ 与 Python 代理）的通信方式从 REST/HTTP 升级到 **gRPC**，以获得更高的性能和更强的类型安全。
-   **线程池背压机制**:
    -   为线程池实现背压（Back-pressure）策略，如 **降级、熔断或直接拒绝请求**。这可以防止在极端高并发下，I/O线程（生产者）的生产速度远超工作线程（消费者）的处理速度，导致任务队列无限增长和内存耗尽。
-   **数据库并发优化**:
    -   为每个工作线程 (`worker thread`) 分配一个 **线程局部 (`thread_local`) 的SQLite句柄**。这样每个线程可以独立操作数据库，从而使用 `SQLITE_OPEN_NOMUTEX` 模式来避免线程间的锁竞争，大幅提升写入性能。
-   **处理数据库繁忙**:
    -   在代码中专门处理 `SQLITE_BUSY` 返回码，而不是直接抛出异常。可以实现一个带有退避策略的重试循环，以应对暂时的数据库锁定。

### 3. 数据库与持久化 (Database & Persistence)

-   **时间戳精度**:
    -   将数据库中记录日志时间的 `received_at` 字段类型从 `TIMESTAMP` 改为 **整数类型的Unix时间戳**。在高负载下，任务从接收到执行之间可能存在延迟，使用时间戳能更精确地记录事件发生的时间。

### 4. API与外部集成 (API & External Integration)

-   **统一API管理**:
    -   针对 `ai` 模块，建立一个统一的API管理层，用于适配和处理来自不同AI厂商的、风格各异的 RESTful API。

### 5. 可观测性 (Observability)

-   **Trace ID 优化**:
    -   研究通过额外一轮哈希或其他算法来缩短 `trace_id` 的长度，使其在日志和监控系统中更易于阅读、存储和索引。

### 6. 测试环境 (Testing)

-   **独立的压测客户端**:
    -   使用独立的机器（例如，阿里云的2核2G服务器）作为`wrk`压测的客户端，而不是在服务器本机上同时运行客户端和服务端。这可以避免因资源竞争（特别是CPU）导致测试结果不准确。

### 7. AI上下文管理策略 (AI Context Management Strategy)

为了解决大语言模型（LLM）的上下文窗口（Context Window）限制问题，特别是在处理长日志和多轮对话时，我们计划采用分阶段的演进策略来管理对话历史。

-   **第一阶段：基本安全策略 (截断/滑动窗口)**
    -   **目标**：保证程序在任何情况下都不会因为Token超限而崩溃。
    -   **实现**：在将历史记录传递给AI之前，检查其总长度。如果超出安全阈值，则采用“滑动窗口”策略，只保留最近的N轮对话，或直接截断（丢弃）最早的对话记录。
    -   **优缺点**：实现最简单，能有效保证程序健壮性，但可能会丢失重要的早期上下文。

-   **第二阶段：AI辅助的上下文摘要**
    -   **目标**：在节省Token的同时，更智能地保留长期记忆。
    -   **实现**：当对话历史达到一定长度时，触发一个特殊的AI任务，要求AI将当前的对话历史压缩成一段精简的摘要。在后续的对话中，使用这个摘要来代替冗长的原始历史记录。
    -   **优缺点**：相比滑动窗口能更好地保留上下文的连贯性，但存在AI摘要时信息丢失的风险，且实现相对复杂。

-   **第三阶段：向量数据库与RAG (检索增强生成)**
    -   **目标**：实现高效、精准的长期记忆和海量知识管理。
    -   **实现**：将每一轮对话都通过Embedding模型转化为向量，并存入专门的向量数据库。当有新问题时，通过向量相似度搜索，从数据库中检索出最相关的几段历史对话或外部知识，然后将其注入到Prompt中，供AI参考。
    -   **优缺点**：最强大和可扩展的方案，但架构复杂度最高，需要引入向量数据库等新组件。

### 8. 未来思考 (Future Considerations)

-   **服务启动编排**:
    -   考虑如何优雅地启动和管理C++主服务器和Python AI代理服务。这可能涉及到C++调用shell脚本来启动Python服务，或者使用更高级的服务管理工具（如`systemd`、`supervisor`或容器编排）。
-   **AI上下文维护位置**:
    -   深入探讨AI上下文管理（如历史记录的存储、压缩、检索）的最佳位置。是在Python代理服务中进行，还是在C++主服务器中进行？这需要权衡性能、复杂性、可扩展性和语言特性。





    配置语言选择。